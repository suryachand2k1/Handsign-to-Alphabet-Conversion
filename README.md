# Voice for Voiceless: Real-Time Sign Language Recognition

## Overview
This project aims to provide a voice for those with speech and hearing impairments by developing a real-time American Sign Language (ASL) recognition system. It's designed to facilitate easier communication for the deaf and mute community.

### Objectives
- Develop an application for sign detection and conversion to audio and text.
- Improve accuracy and ease of communication using computer vision and machine learning.

## Existing System
- Current systems use physical components and sensors, leading to inconvenience and high costs.
- Machine learning improvements have been made, but accuracy remains a challenge.

## Proposed System
- Utilizing hand signs as key points for accuracy.
- Implementing computer vision for capturing signs and gestures.
- Planning an application that accomplishes tasks faster, easier, and more accurately.

### Software Requirements
- Python 3.9, HTML, PHP, CSS, JavaScript
- Tensorflow, OpenCV, NumPy, Matplotlib, PIL, Keras, Flask

## Achievements
- Achieved 97.3% accuracy on our dataset but will generally be a bit lower for unseen data.
- Enhanced predictions for symbols with similar appearances.
- Future upgrades include facial expressions and body language recognition.

## Future Enhancements
- Improving accuracy in complex backgrounds and low light conditions.
- Developing an audio-to-sign language translation using avatars.
